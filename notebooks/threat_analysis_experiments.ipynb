{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIH PS1 - Threat Analysis Experiments\n",
    "\n",
    "This notebook contains experiments and analysis for the cybersecurity threat detector.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.text_processing import TextProcessor\n",
    "from utils.url_parser import URLParser\n",
    "from utils.data_loader import DataLoader\n",
    "\n",
    "# Initialize utilities\n",
    "text_processor = TextProcessor()\n",
    "url_parser = URLParser()\n",
    "data_loader = DataLoader()\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "sample_data = data_loader.load_sample_data()\n",
    "training_df = data_loader.get_training_data()\n",
    "\n",
    "print(\"üìä Data Statistics:\")\n",
    "stats = data_loader.get_data_stats()\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüìã Sample Data:\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test text processing on sample data\n",
    "sample_texts = [\n",
    "    \"URGENT: Your account will be suspended! Click here now!\",\n",
    "    \"Thank you for your recent purchase from Amazon.\",\n",
    "    \"Congratulations! You've won $1,000,000 in our lottery!\"\n",
    "]\n",
    "\n",
    "print(\"üîç Text Analysis Results:\")\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    features = text_processor.extract_features(text)\n",
    "    print(f\"\\nText {i}: {text[:50]}...\")\n",
    "    print(f\"  Suspicious Score: {features['suspicious_score']:.2f}\")\n",
    "    print(f\"  Urgency Words: {features['urgency_words']}\")\n",
    "    print(f\"  URLs Found: {len(features['urls'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL Analysis Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test URL analysis\n",
    "sample_urls = [\n",
    "    \"http://192.168.1.1/login\",\n",
    "    \"https://amazon.com/orders\",\n",
    "    \"http://bit.ly/suspicious-link\",\n",
    "    \"https://secure-bank-verify.com/urgent-update\"\n",
    "]\n",
    "\n",
    "print(\"üîó URL Analysis Results:\")\n",
    "for i, url in enumerate(sample_urls, 1):\n",
    "    risk_info = url_parser.calculate_url_risk(url)\n",
    "    print(f\"\\nURL {i}: {url}\")\n",
    "    print(f\"  Risk Score: {risk_info['risk_score']:.2f}\")\n",
    "    print(f\"  Risk Level: {risk_info['risk_level']}\")\n",
    "    print(f\"  Issues: {risk_info['issues']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Risk score distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(training_df['risk_score'], bins=20, alpha=0.7, color='skyblue')\n",
    "plt.title('Risk Score Distribution')\n",
    "plt.xlabel('Risk Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Label distribution\n",
    "plt.subplot(2, 2, 2)\n",
    "training_df['label'].value_counts().plot(kind='bar', color=['green', 'orange', 'red'])\n",
    "plt.title('Label Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Content type distribution\n",
    "plt.subplot(2, 2, 3)\n",
    "training_df['type'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Content Type Distribution')\n",
    "\n",
    "# Risk score by label\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(data=training_df, x='label', y='risk_score')\n",
    "plt.title('Risk Score by Label')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for machine learning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Filter text data for ML experiment\n",
    "text_data = training_df[training_df['type'] == 'text'].copy()\n",
    "\n",
    "if len(text_data) > 0:\n",
    "    # Vectorize text\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "    X = vectorizer.fit_transform(text_data['content'])\n",
    "    y = text_data['label']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"üéØ Model Accuracy: {accuracy:.2f}\")\n",
    "    print(\"\\nüìä Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough text data for ML experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Test processing speed\n",
    "test_texts = [\"This is a test message\"] * 100\n",
    "test_urls = [\"https://example.com\"] * 100\n",
    "\n",
    "# Text processing speed\n",
    "start_time = time.time()\n",
    "for text in test_texts:\n",
    "    text_processor.extract_features(text)\n",
    "text_time = time.time() - start_time\n",
    "\n",
    "# URL processing speed\n",
    "start_time = time.time()\n",
    "for url in test_urls:\n",
    "    url_parser.calculate_url_risk(url)\n",
    "url_time = time.time() - start_time\n",
    "\n",
    "print(\"‚ö° Performance Results:\")\n",
    "print(f\"  Text Processing: {text_time:.3f}s for 100 texts ({text_time*10:.1f}ms per text)\")\n",
    "print(f\"  URL Processing: {url_time:.3f}s for 100 URLs ({url_time*10:.1f}ms per URL)\")\n",
    "print(f\"  Total Throughput: {200/(text_time + url_time):.1f} items/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the capabilities of our threat detection utilities:\n",
    "\n",
    "- ‚úÖ Text processing and feature extraction\n",
    "- ‚úÖ URL analysis and risk assessment\n",
    "- ‚úÖ Data loading and management\n",
    "- ‚úÖ Performance benchmarking\n",
    "- ‚úÖ Machine learning experiments\n",
    "\n",
    "Use this notebook to experiment with new features and improve the detection algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
